{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_lasso(X_train, y_train, X_test, y_test):\n",
    "    MSE_train= []\n",
    "    CV_train = []\n",
    "    MSE_test= []\n",
    "    CV_test = []\n",
    "    MAE_train = []\n",
    "    MAPE_train =[]\n",
    "    MAE_test = []\n",
    "    MAPE_test =[]\n",
    "    \n",
    "    #  Lasso\n",
    "    lasso = Lasso(alpha = 0.016)\n",
    "    y_pred_lasso_train = lasso.fit(X_train, y_train).predict(X_train)\n",
    "    y_pred_lasso = lasso.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    MSE_train.append(np.mean((y_pred_lasso_train - y_train) ** 2))\n",
    "    MSE_test.append(np.mean((y_pred_lasso - y_test) ** 2))\n",
    "     \n",
    "    scores1 = cross_val_score(lasso, X_train, y_train, cv=10)\n",
    "    CV_train.append([scores1.mean(), scores1.std() * 2])\n",
    "    scores2 = cross_val_score(lasso, X_test, y_test, cv=10)\n",
    "    CV_test.append([scores2.mean(), scores2.std() * 2])\n",
    "    \n",
    "    MAE_train.append(metrics.mean_absolute_error(y_train, y_pred_lasso_train))\n",
    "    MAE_test.append(metrics.mean_absolute_error(y_test, y_pred_lasso))\n",
    "    \n",
    "    MAPE_train.append(np.mean(np.abs((y_train - y_pred_lasso_train) / y_train)) * 100)\n",
    "    MAPE_test.append(np.mean(np.abs((y_test - y_pred_lasso) / y_test)) * 100)\n",
    "\n",
    "    return MSE_train[0], CV_train[0], MSE_test[0], CV_test[0], MAE_train[0], MAPE_train[0], MAE_test[0], MAPE_test[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_svr(X_train, y_train, X_test, y_test):\n",
    "    MSE_train= []\n",
    "    CV_train = []\n",
    "    MSE_test= []\n",
    "    CV_test = []\n",
    "    MAE_train = []\n",
    "    MAPE_train =[]\n",
    "    MAE_test = []\n",
    "    MAPE_test =[]\n",
    "    \n",
    "    # SVR\n",
    "    svr = svm.SVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = svr.predict(X_train)\n",
    "    y_pred_test = svr.predict(X_test)\n",
    "    \n",
    "    MSE_train.append(np.mean((y_pred_train - y_train) ** 2))\n",
    "    MSE_test.append(np.mean((y_pred_test - y_test) ** 2))\n",
    "    \n",
    "    scores1 = cross_val_score(svr, X_train, y_train, cv=10)\n",
    "    CV_train.append([scores1.mean(), scores1.std() * 2])\n",
    "    scores2 = cross_val_score(svr, X_test, y_test, cv=10)\n",
    "    CV_test.append([scores2.mean(), scores2.std() * 2])\n",
    "    \n",
    "    MAE_train.append(metrics.mean_absolute_error(y_train, y_pred_train))\n",
    "    MAE_test.append(metrics.mean_absolute_error(y_test, y_pred_test))\n",
    "    \n",
    "    MAPE_train.append(np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100)\n",
    "    MAPE_test.append(np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100)\n",
    "\n",
    "\n",
    "    return MSE_train[0], CV_train[0], MSE_test[0], CV_test[0], MAE_train[0], MAPE_train[0], MAE_test[0], MAPE_test[0], y_pred_train, y_pred_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_rf(X_train, y_train, X_test, y_test):\n",
    "    MSE_train= []\n",
    "    CV_train = []\n",
    "    MSE_test= []\n",
    "    CV_test = []\n",
    "    MAE_train = []\n",
    "    MAPE_train =[]\n",
    "    MAE_test = []\n",
    "    MAPE_test =[]\n",
    "    \n",
    "    # RandomForest\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    \n",
    "    MSE_train.append(np.mean((y_pred_train - y_train) ** 2))\n",
    "    MSE_test.append(np.mean((y_pred_test - y_test) ** 2))\n",
    "    \n",
    "    scores1 = cross_val_score(rf, X_train, y_train, cv=10)\n",
    "    CV_train.append([scores1.mean(), scores1.std() * 2])\n",
    "    scores2 = cross_val_score(rf, X_test, y_test, cv=10)\n",
    "    CV_test.append([scores2.mean(), scores2.std() * 2])\n",
    "    \n",
    "    MAE_train.append(metrics.mean_absolute_error(y_train, y_pred_train))\n",
    "    MAE_test.append(metrics.mean_absolute_error(y_test, y_pred_test))\n",
    "    \n",
    "    MAPE_train.append(np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100)\n",
    "    MAPE_test.append(np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100)\n",
    "\n",
    "\n",
    "    return MSE_train[0], CV_train[0], MSE_test[0], CV_test[0], MAE_train[0], MAPE_train[0], MAE_test[0], MAPE_test[0], y_pred_train, y_pred_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_gbr(X_train, y_train, X_test, y_test):\n",
    "    MSE_train= []\n",
    "    CV_train = []\n",
    "    MSE_test= []\n",
    "    CV_test = []\n",
    "    MAE_train = []\n",
    "    MAPE_train =[]\n",
    "    MAE_test = []\n",
    "    MAPE_test =[]\n",
    "    \n",
    "    # GradientBoosting\n",
    "    params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,\n",
    "              'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    clf = GradientBoostingRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "                     \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)   \n",
    "                     \n",
    "    MSE_train.append(np.mean((y_pred_train - y_train) ** 2))\n",
    "    MSE_test.append(np.mean((y_pred_test - y_test) ** 2))\n",
    "    \n",
    "    scores1 = cross_val_score( clf, X_train, y_train, cv=10)\n",
    "    CV_train.append([scores1.mean(), scores1.std() * 2])\n",
    "    scores2 = cross_val_score( clf, X_test, y_test, cv=10)\n",
    "    CV_test.append([scores2.mean(), scores2.std() * 2])\n",
    "    \n",
    "    MAE_train.append(metrics.mean_absolute_error(y_train, y_pred_train))\n",
    "    MAE_test.append(metrics.mean_absolute_error(y_test, y_pred_test))\n",
    "    \n",
    "    MAPE_train.append(np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100)\n",
    "    MAPE_test.append(np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100)\n",
    "    \n",
    "    return MSE_train[0], CV_train[0], MSE_test[0], CV_test[0], MAE_train[0], MAPE_train[0], MAE_test[0], MAPE_test[0], y_pred_train, y_pred_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculating embeddings (finding best parameters: 'p' and 'q')\n",
    "# Source: https://github.com/aditya-grover/node2vec\n",
    "values = [0.25,0.5,1,2,4] # d=64\n",
    "for x in values:\n",
    "    for y in values:\n",
    "        %run ./node2vec-master/src/main.py --input ./Data/edgelist_train.txt --output ./Data/emb/out{x}_{y}.txt --q {x} --p {y} --weighted\n",
    "        %run ./node2vec-master/src/main.py --input ./Data/edgelist_2017.txt --output ./Data/emb/out_x{x}_{y}.txt --q {x} --p {y} --weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finding the best 'd' parameter for learning (with p=0.25 and q=2)\n",
    "values_d = [16,32,64,128,256]\n",
    "for d in values_d:\n",
    "    %run ./node2vec-master/src/main.py --input ./Data/edgelist_train.txt --output ./Data/emb/out_d_{d}.txt --dimensions {d} --q 2 --p 0.25 --weighted\n",
    "    %run ./node2vec-master/src/main.py --input ./Data/edgelist_2017.txt --output ./Data/emb/out_x_d_{d}.txt --dimensions {d} --q 2 --p 0.25 --weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define edge embbeding functions\n",
    "def avg_sum(v1, v2):\n",
    "    return (np.array(v1)+np.array(v2))/2\n",
    "\n",
    "def mult(v1, v2):\n",
    "    return np.array(v1)*np.array(v2)\n",
    "\n",
    "def w_l1(v1, v2):\n",
    "    return np.abs(np.array(v1)-np.array(v2))\n",
    "\n",
    "def w_l2(v1, v2):\n",
    "    return (np.array(v1)-np.array(v2))**2\n",
    "\n",
    "def nw_l1(v1, v2, graph, n1, n2, embs ):\n",
    "    neig1 = [n for n in graph.neighbors(n1)]\n",
    "    neig2 = [n for n in graph.neighbors(n2)]\n",
    "    sum1 = np.zeros(len(v1))\n",
    "    sum2 = np.zeros(len(v2))\n",
    "    for n in neig1:\n",
    "        sum1 += np.array(embs[int(n)])\n",
    "    for n in neig2:\n",
    "        sum2 += np.array(embs[int(n)])\n",
    "    return np.abs((sum1+np.array(v1))/(len(neig1)+1)-(sum2+np.array(v2))/(len(neig2)+1))\n",
    "\n",
    "def nw_l2(v1, v2, graph, n1, n2, embs ):\n",
    "    neig1 = [n for n in graph.neighbors(n1)]\n",
    "    neig2 = [n for n in graph.neighbors(n2)]\n",
    "    sum1 = np.zeros(len(v1))\n",
    "    sum2 = np.zeros(len(v2))\n",
    "    for n in neig1:\n",
    "        sum1 += np.array(embs[int(n)])\n",
    "    for n in neig2:\n",
    "        sum2 += np.array(embs[int(n)])\n",
    "    return ((sum1+np.array(v1))/(len(neig1)+1)-(sum2+np.array(v2))/(len(neig2)+1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Loading data ##\n",
    "Graph_train = nx.read_weighted_edgelist(\"./Data/edgelist_train.txt\", delimiter=' ',nodetype=int)\n",
    "Graph_2017 = nx.read_weighted_edgelist(\"./Data/edgelist_2017.txt\", delimiter=' ',nodetype=int)\n",
    "f_train = open('./Data/edgelist_train.txt')\n",
    "f_2017 = open('./Data/edgelist_2017.txt')\n",
    "edges_train = []\n",
    "edges_2017 = []\n",
    "for line in f_train:\n",
    "    edges_train.append(line.split(' '))\n",
    "for line in f_2017:\n",
    "    edges_2017.append(line.split(' '))\n",
    "f_train.close()\n",
    "f_2017.close()\n",
    "for i in range(len(edges_train)):\n",
    "    edges_train[i][2] = edges_train[i][2][:-1]\n",
    "for i in range(len(edges_2017)):\n",
    "    edges_2017[i][2] = edges_2017[i][2][:-1]\n",
    "f_emb_train = open('./Data/emb/out_d_'+str(16)+'.txt')\n",
    "f_emb_2017 = open('./Data/emb/out_x_d_'+str(16)+'.txt')\n",
    "emb_train = []\n",
    "emb_2017 = []\n",
    "for line in f_emb_train:\n",
    "    emb_train.append(line.split(' '))\n",
    "for line in f_emb_2017:\n",
    "    emb_2017.append(line.split(' '))\n",
    "f_emb_train.close()\n",
    "f_emb_2017.close()\n",
    "for i in range(len(emb_2017)):\n",
    "    emb_2017[i][len(emb_2017[i])-1] = emb_2017[i][len(emb_2017[i])-1][:-1]\n",
    "emb_2017_dict = {} \n",
    "for i in range(1,len(emb_2017)):\n",
    "    emb_2017_dict[int(emb_2017[i][0])] = [float(j) for j in emb_2017[i][1:]]\n",
    "for i in range(len(emb_train)):\n",
    "    emb_train[i][len(emb_train[i])-1] = emb_train[i][len(emb_train[i])-1][:-1]\n",
    "emb_train_dict = {} \n",
    "for i in range(1,len(emb_train)):\n",
    "    emb_train_dict[int(emb_train[i][0])] = [float(j) for j in emb_train[i][1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 1 ##\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for e in edges_2017:\n",
    "    emb1 = emb_2017_dict[int(e[0])]\n",
    "    emb2 = emb_2017_dict[int(e[1])]\n",
    "    w = float(e[2])\n",
    "    y_test.append(w)\n",
    "    res = nw_l2(emb1, emb2, Graph_2017,int(e[0]),int(e[1]),emb_2017_dict)\n",
    "    X_test.append(res)\n",
    "for e in edges_train:\n",
    "    emb1 = emb_train_dict[int(e[0])]\n",
    "    emb2 = emb_train_dict[int(e[1])]\n",
    "    w = float(e[2])\n",
    "    y_train.append(w)\n",
    "    res = nw_l2(emb1, emb2, Graph_train,int(e[0]),int(e[1]),emb_train_dict)\n",
    "    X_train.append(res)\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test, y_pred_train, y_pred_test  = model_svr(X_train, y_train, X_test, y_test)\n",
    "print('MSE: ' + str(mse_train))\n",
    "print('MAE: ' + str(mae_train))\n",
    "print('MAPE: ' + str(mape_train) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 3 ##\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for e in edges_2017:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_2017, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    w = float(e[2])\n",
    "    y_test.append(w)\n",
    "    res = np.array([pref_att, jac, aa])\n",
    "    X_test.append(res)\n",
    "for e in edges_train:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_train, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    w = float(e[2])\n",
    "    y_train.append(w)\n",
    "    res = np.array([pref_att, jac, aa])\n",
    "    X_train.append(res)\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test, y_pred_train, y_pred_test  = model_svr(X_train, y_train, X_test, y_test)\n",
    "print('MSE: ' + str(mse_train))\n",
    "print('MAE: ' + str(mae_train))\n",
    "print('MAPE: ' + str(mape_train) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## 4 ##\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "# betw_2017 = nx.betweenness_centrality(Graph_2017)\n",
    "# clos_2017 = nx.closeness_centrality(Graph_2017)\n",
    "for e in edges_2017:\n",
    "    cl_coef = nx.clustering(Graph_2017, int(e[0])) + nx.clustering(Graph_2017, int(e[1]))\n",
    "    betw = betw_2017.get(int(e[0])) + betw_2017.get(int(e[0]))\n",
    "    clos = clos_2017.get(int(e[0])) + clos_2017.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_2017, int(e[0]),int(e[1]))\n",
    "    w = float(e[2])\n",
    "    y_test.append(w)\n",
    "    res = np.array([cl_coef, betw, clos, sp])\n",
    "    X_test.append(res)\n",
    "# betw_train = nx.betweenness_centrality(Graph_train)\n",
    "# clos_train = nx.closeness_centrality(Graph_train)\n",
    "for e in edges_train:\n",
    "    cl_coef = nx.clustering(Graph_train, int(e[0])) + nx.clustering(Graph_train, int(e[1]))\n",
    "    betw = betw_train.get(int(e[0])) + betw_train.get(int(e[0]))\n",
    "    clos = clos_train.get(int(e[0])) + clos_train.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_train, int(e[0]),int(e[1]))\n",
    "    w = float(e[2])\n",
    "    y_train.append(w)\n",
    "    res = np.array([cl_coef, betw, clos, sp])\n",
    "    X_train.append(res)\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test, y_pred_train, y_pred_test  = model_svr(X_train, y_train, X_test, y_test)\n",
    "print('MSE: ' + str(mse_train))\n",
    "print('MAE: ' + str(mae_train))\n",
    "print('MAPE: ' + str(mape_train) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## 3 + 4 ##\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for e in edges_2017:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_2017, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    cl_coef = nx.clustering(Graph_2017, int(e[0])) + nx.clustering(Graph_2017, int(e[1]))\n",
    "    betw = betw_2017.get(int(e[0])) + betw_2017.get(int(e[0]))\n",
    "    clos = clos_2017.get(int(e[0])) + clos_2017.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_2017, int(e[0]),int(e[1]))\n",
    "    w = float(e[2])\n",
    "    y_test.append(w)\n",
    "    res = np.array([pref_att, jac, aa, cl_coef, betw, clos, sp])\n",
    "    X_test.append(res)\n",
    "for e in edges_train:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_train, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    cl_coef = nx.clustering(Graph_train, int(e[0])) + nx.clustering(Graph_train, int(e[1]))\n",
    "    betw = betw_train.get(int(e[0])) + betw_train.get(int(e[0]))\n",
    "    clos = clos_train.get(int(e[0])) + clos_train.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_train, int(e[0]),int(e[1]))\n",
    "    w = float(e[2])\n",
    "    y_train.append(w)\n",
    "    res = np.array([pref_att, jac, aa, cl_coef, betw, clos, sp])\n",
    "    X_train.append(res)\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test, y_pred_train, y_pred_test  = model_svr(X_train, y_train, X_test, y_test)\n",
    "print('MSE: ' + str(mse_train))\n",
    "print('MAE: ' + str(mae_train))\n",
    "print('MAPE: ' + str(mape_train) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## 1 + 4 ##\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for e in edges_2017:\n",
    "    cl_coef = nx.clustering(Graph_2017, int(e[0])) + nx.clustering(Graph_2017, int(e[1]))\n",
    "    betw = betw_2017.get(int(e[0])) + betw_2017.get(int(e[0]))\n",
    "    clos = clos_2017.get(int(e[0])) + clos_2017.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_2017, int(e[0]),int(e[1]))\n",
    "    emb1 = emb_2017_dict[int(e[0])]\n",
    "    emb2 = emb_2017_dict[int(e[1])]\n",
    "    nw = nw_l2(emb1, emb2, Graph_2017,int(e[0]),int(e[1]),emb_2017_dict)\n",
    "    w = float(e[2])\n",
    "    y_test.append(w)\n",
    "    res = np.concatenate((np.array([cl_coef, betw, clos, sp]), nw))\n",
    "    X_test.append(res)\n",
    "for e in edges_train:\n",
    "    cl_coef = nx.clustering(Graph_train, int(e[0])) + nx.clustering(Graph_train, int(e[1]))\n",
    "    betw = betw_train.get(int(e[0])) + betw_train.get(int(e[0]))\n",
    "    clos = clos_train.get(int(e[0])) + clos_train.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_train, int(e[0]),int(e[1]))\n",
    "    emb1 = emb_train_dict[int(e[0])]\n",
    "    emb2 = emb_train_dict[int(e[1])]\n",
    "    nw = nw_l2(emb1, emb2, Graph_train,int(e[0]),int(e[1]),emb_train_dict)\n",
    "    w = float(e[2])\n",
    "    y_train.append(w)\n",
    "    res = np.concatenate((np.array([cl_coef, betw, clos, sp]), nw))\n",
    "    X_train.append(res)\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test, y_pred_train, y_pred_test  = model_svr(X_train, y_train, X_test, y_test)\n",
    "print('MSE: ' + str(mse_train))\n",
    "print('MAE: ' + str(mae_train))\n",
    "print('MAPE: ' + str(mape_train) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## 1 + 3 ##\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for e in edges_2017:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_2017, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    emb1 = emb_2017_dict[int(e[0])]\n",
    "    emb2 = emb_2017_dict[int(e[1])]\n",
    "    nw = nw_l2(emb1, emb2, Graph_2017,int(e[0]),int(e[1]),emb_2017_dict)\n",
    "    w = float(e[2])\n",
    "    y_test.append(w)\n",
    "    res = np.concatenate((np.array([pref_att, jac, aa]), nw))\n",
    "    X_test.append(res)\n",
    "for e in edges_train:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_train, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    emb1 = emb_train_dict[int(e[0])]\n",
    "    emb2 = emb_train_dict[int(e[1])]\n",
    "    nw = nw_l2(emb1, emb2, Graph_train,int(e[0]),int(e[1]),emb_train_dict)\n",
    "    w = float(e[2])\n",
    "    y_train.append(w)\n",
    "    res = np.concatenate((np.array([pref_att, jac, aa]), nw))\n",
    "    X_train.append(res)\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test, y_pred_train, y_pred_test  = model_svr(X_train, y_train, X_test, y_test)\n",
    "print('MSE: ' + str(mse_train))\n",
    "print('MAE: ' + str(mae_train))\n",
    "print('MAPE: ' + str(mape_train) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## 1 + 3 + 4 ##\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for e in edges_2017:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_2017, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_2017, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    cl_coef = nx.clustering(Graph_2017, int(e[0])) + nx.clustering(Graph_2017, int(e[1]))\n",
    "    betw = betw_2017.get(int(e[0])) + betw_2017.get(int(e[0]))\n",
    "    clos = clos_2017.get(int(e[0])) + clos_2017.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_2017, int(e[0]),int(e[1]))\n",
    "    emb1 = emb_2017_dict[int(e[0])]\n",
    "    emb2 = emb_2017_dict[int(e[1])]\n",
    "    nw = nw_l2(emb1, emb2, Graph_2017,int(e[0]),int(e[1]),emb_2017_dict)\n",
    "    w = float(e[2])\n",
    "    y_test.append(w)\n",
    "    res = np.concatenate((np.array([pref_att, jac, aa, cl_coef, betw, clos, sp]), nw))\n",
    "    X_test.append(res)\n",
    "for e in edges_train:\n",
    "    pref_att = len(list(nx.common_neighbors(Graph_train, int(e[0]),int(e[1]))))\n",
    "    jac = list(nx.jaccard_coefficient(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    aa = list(nx.adamic_adar_index(Graph_train, [(int(e[0]),int(e[1]))]))[0][2]\n",
    "    cl_coef = nx.clustering(Graph_train, int(e[0])) + nx.clustering(Graph_train, int(e[1]))\n",
    "    betw = betw_train.get(int(e[0])) + betw_train.get(int(e[0]))\n",
    "    clos = clos_train.get(int(e[0])) + clos_train.get(int(e[0]))\n",
    "    sp = nx.shortest_path_length(Graph_train, int(e[0]),int(e[1]))\n",
    "    emb1 = emb_train_dict[int(e[0])]\n",
    "    emb2 = emb_train_dict[int(e[1])]\n",
    "    nw = nw_l2(emb1, emb2, Graph_train,int(e[0]),int(e[1]),emb_train_dict)\n",
    "    w = float(e[2])\n",
    "    y_train.append(w)\n",
    "    res = np.concatenate((np.array([pref_att, jac, aa, cl_coef, betw, clos, sp]), nw))\n",
    "    X_train.append(res)\n",
    "mse_train, cv_train, mse_test,cv_test, mae_train, mape_train, mae_test,mape_test, y_pred_train, y_pred_test  = model_svr(X_train, y_train, X_test, y_test)\n",
    "print('MSE: ' + str(mse_train))\n",
    "print('MAE: ' + str(mae_train))\n",
    "print('MAPE: ' + str(mape_train) + ' %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
